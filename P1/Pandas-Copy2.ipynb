{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd64507f",
   "metadata": {},
   "source": [
    "# Preprocessing data with pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ce3da1",
   "metadata": {},
   "source": [
    "**Names**\n",
    "\n",
    "Cristina Mora Velasco\n",
    "___________________________________\n",
    "\n",
    "Francisco Miguel Galvan MuÃ±oz\n",
    "___________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578107c2",
   "metadata": {},
   "source": [
    "## Pandas\n",
    "\n",
    "Python Data Analysis Library) an open source (BSD) library designed to process data with high performance.\n",
    "Some definitions:\n",
    "\n",
    "- **Dataframe**: the main structure of Pandas. Is similat to a database table or a excell leaf.\n",
    "- **CSV**: Is the most commonly used dataset format in machine learning. It is a text file with training each one stored on one line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f06ebb",
   "metadata": {},
   "source": [
    "Load datase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "474a1a06",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dato.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m gameSales \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdato.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dato.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "gameSales = pd.read_csv('dato.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22efe571",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(gameSales)\n",
    "display(gameSales.head(n=4));\n",
    "display(gameSales.tail(n=4));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922885e3",
   "metadata": {},
   "source": [
    "Find NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64422ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "gameSales.isna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8793c98",
   "metadata": {},
   "source": [
    "any(axis) function check if any value in each row (index) is True. axis\t0 1 ('index''columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184cee28",
   "metadata": {},
   "outputs": [],
   "source": [
    "gameSales[gameSales.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5413efa6",
   "metadata": {},
   "source": [
    "we can looking for a specific column by filtering by column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02520e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "gameSales[gameSales[\"Global_Sales\"].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0468f885",
   "metadata": {},
   "source": [
    "there are other useful methods for finding errors such as:\n",
    "- notna()\n",
    "- isnull()\n",
    "- notnull()\n",
    "\n",
    "We can search for a specific value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660c6bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "gameSales[gameSales[\"Publisher\"] == \"Capcom\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fadab45",
   "metadata": {},
   "source": [
    "Now we are looking for the best-selling video game in Japan.\n",
    "For this we look at the column types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157a3b2a",
   "metadata": {},
   "source": [
    "but it gives us an error because 3.77 is not convertible to float, we have to change the character to a dot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1fbd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "gameSales[\"JP_Sales\"] = gameSales[\"JP_Sales\"].apply(lambda x:  str(x).replace(\",\",\".\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7890609",
   "metadata": {},
   "source": [
    "now we are left with only the overall sales column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1199214b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostPlatformGame = mostPlatformGame.drop('NA_Sales', axis=1)\n",
    "mostPlatformGame = mostPlatformGame.drop('EU_Sales', axis=1)\n",
    "mostPlatformGame = mostPlatformGame.drop('JP_Sales', axis=1)\n",
    "mostPlatformGame = mostPlatformGame.drop('Other_Sales', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a67b172",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(mostPlatformGame)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df2ffe8",
   "metadata": {},
   "source": [
    "If we want to know which is the best-selling game of all the consoles, we remove the PC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abcfcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostPlatformGame=mostPlatformGame.reset_index()\n",
    "mostPlatformGame = mostPlatformGame.drop(mostPlatformGame[mostPlatformGame.Platform == \"PC\"].index)\n",
    "display(mostPlatformGame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa037c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostPlatformGame[mostPlatformGame[\"Global_Sales\"] == mostPlatformGame[\"Global_Sales\"].max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b022a3",
   "metadata": {},
   "source": [
    "Now let's see which first party game is the best seller on each platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a74c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "firstParty = pd.read_csv('first_party.csv')\n",
    "display(firstParty)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcec4af",
   "metadata": {},
   "source": [
    "We have to make a merge of both tables in order to know which platforms belong to which brand of consoles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871754c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gameSalesMerge = pd.merge(gameSales,firstParty,how='outer',on=('Platform'), indicator=True)\n",
    "display(gameSalesMerge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34110a4",
   "metadata": {},
   "source": [
    "Now we group by first_Party and keep the one with the largest sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133bf273",
   "metadata": {},
   "outputs": [],
   "source": [
    "gameSalesMergeGB = gameSalesMerge.groupby(\"First_Party\")\n",
    "gameSalesMergeFilter = gameSalesMergeGB.max(numeric_only=True)\n",
    "display(gameSalesMergeFilter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345d34ec",
   "metadata": {},
   "source": [
    "# Exercises\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ef5c56-9f93-4531-829a-02788fa44d12",
   "metadata": {},
   "source": [
    "## Pandas 5p\n",
    "\n",
    "1. Get the platform that has no First_Party and the First_Party console that has no sales.\n",
    "   \n",
    "3. Cleans the dataset of numerical errors (NaN) by imputing the average value of each column to the missing data.\n",
    "4. In the work folder there is a csv about video game developers (video-games-developers.csv). Clean the dataframe from missing or erroneous values in the following fields (Country, Est., City)\n",
    "5. List the spanish developers\n",
    "6. List developers that were created before 2000\n",
    "\n",
    "**Answer in this Notebook**\n",
    "\n",
    "## Python 5p\n",
    "\n",
    "Realiza un pequeÃ±o juego en modo texto de un RPG. En este RPG tenemos la clase Gerrero, Mago y Enano que deben enfrentarse a 3 orcos que tendrÃ¡n valores de vida y ataque diferente en funciÃ³n de la partida. Para la nomeclatura de la prÃ¡ctica vamos a emplear las siguientes convenciones. dX siendo X un nÃºmero implica un dado de X, por ejemplo d6 es un dado de 6. Si decimos que el daÃ±o del guerrero es 2xd6 indicamos que tira dos dados de 6.\n",
    "Estadisticas de los protagonistas:\n",
    "* El Mago puede atacar o curar a los aliados. Es el que tiene menos vida (a determinar por vosotros) La curaciÃ³n resultante es un d6 y debe establecerse a que jugador quiero curar mediante el prompt. El ataque es un d6 pero afecta a todos los enemigos, no sÃ³lo al seleccionado.\n",
    "* El guerrero tiene vida media, es el mas poderoso atacando (3xd6)\n",
    "* El enano es el que tiene mas vida. Debe tener mas vida que el guerrero y el mago juntos. Su ataque es 2 dados de 6.\n",
    "\n",
    "Cada turno ataca nuestro equipo de heroes primero y luego los enemigos. Los enemigos pueden atacar como quiera el alumno, aleatoriamente o con algÃºn tipo de estrategia (por ejemplo que ataque el que mÃ¡s vida tenga o el mÃ¡s fuerte)\n",
    "\n",
    "En el turno el jugador debe elegir usando un prompt el personaje que usa y ese serÃ¡ el que reciba el daÃ±o y el que ataque. Lo mismo para la IA que contrala a los orcos. Salvo en el caso del mago, el orco que recibirÃ¡ el daÃ±o serÃ¡ el que sea elegido. Si se elige el mago, entonces se deberÃ¡ preguntar que desea hacer el jugador, atacar o curar. En el caso de curar tendrÃ¡ que preguntar a cual de sus compaÃ±eros quiere curar. No se pueden curar personajes muertos.\n",
    "\n",
    "Si uno de los enemigos o de los aliados muere, el que ha realizado la muerte (sea jugador o IA) puede atacar otra vez en el mismo turno. Como dijimos antes, siempre ataca primero el jugador.\n",
    "\n",
    "Debe haber registro textual de todo lo que vaya ocurriendo durante el juego.\n",
    "\n",
    "Traza de ejemplo (no es necesario que sea asi):\n",
    "\n",
    "mago(10), guerrero(20), enano (32) --[] -vs- [] -- orco01(10,1xd6), orco01(15,2xd6), orco01(5,3xd6)\n",
    "\n",
    "promt-- mago\n",
    "\n",
    ", guerrero(20), enano (32) --[mago(10)] -vs- [orco01(15,2xd6)] -- orco01(10,1xd6), , orco01(5,3xd6)\n",
    "\n",
    "prompt-- atacar\n",
    "\n",
    "1d6 = 3.\n",
    "\n",
    ", guerrero(20), enano (32) --[mago(10)] -vs- [orco01(12,2xd6)] -- orco01(7,1xd6), , orco01(2,3xd6)\n",
    "\n",
    "ataca orcos 2xd6 = 3+6 = 9\n",
    "\n",
    "mago(1), guerrero(20), enano (32) --[] -vs- [] -- orco01(7,1xd6), orco01(12,2xd6), orco01(2,3xd6)\n",
    "\n",
    "promt-- guerrero\n",
    "\n",
    "mago(1), , enano (32) --[guerrero(20)] -vs- [orco01(7,1xd6)] -- , orco01(12,2xd6), orco01(2,3xd6)\n",
    "\n",
    "ataca guerrero 3 + 2 + 6 = 11\n",
    "\n",
    "orco01 muere\n",
    "\n",
    "mago(1), , enano (32) --[guerrero(20)] -vs- [orco01(12,2xd6)] -- orco01(0,1xd6), , orco01(2,3xd6)\n",
    "\n",
    "ataca guerrero 3+1+2 = 5\n",
    "\n",
    "mago(1), , enano (32) --[guerrero(20)] -vs- [orco01(7,2xd6)] -- orco01(0,1xd6), , orco01(2,3xd6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2f5ccb",
   "metadata": {},
   "source": [
    "**Answer in the gape  below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c76aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ec8b6446-f812-4b40-a494-a4e134605942",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def cleanData(data):\n",
    "    # TO-DO clean the dataframe. Return the dataframe cleaned.\n",
    "\n",
    "    data[\"score\"] = pd.to_numeric(data[\"score\"], errors='coerce')\n",
    "    data[\"user score\"] = pd.to_numeric(data[\"user score\"], errors='coerce')\n",
    "    data[\"score\"] = data[\"score\"].astype(np.float64)\n",
    "    data[\"user score\"] = data[\"user score\"].astype(np.float64)\n",
    "    data[\"score\"] = data[\"score\"] / 10\n",
    "    data = data.dropna(subset=[\"score\", \"user score\"])\n",
    "    return data\n",
    "\n",
    "\n",
    "def load_data_csv(path, x_colum, y_colum):\n",
    "    data = pd.read_csv(path)\n",
    "    data = cleanData(data)\n",
    "    X = data[x_colum].to_numpy()\n",
    "    Y = data[y_colum].to_numpy()\n",
    "\n",
    "    print('X: ', X)\n",
    "    print('Y: ', Y)\n",
    "    # Crear grÃ¡fico de lÃ­nea\n",
    "    plt.plot(X, Y, \"bo\", markersize=1)\n",
    "    # AÃ±adir etiquetas y tÃ­tulo\n",
    "    plt.xlabel('Eje X')\n",
    "    plt.ylabel('Eje Y')\n",
    "    plt.title('GrÃ¡fico de LÃ­nea')\n",
    "\n",
    "    # Mostrar grÃ¡fico\n",
    "    plt.show()\n",
    "    return X, Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1338b0d2-998b-46e0-8869-67f8a5eede7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import math\n",
    "\n",
    "\n",
    "class LinearReg:\n",
    "    \"\"\"\n",
    "    Computes the cost function for linear regression.\n",
    "\n",
    "    Args:\n",
    "        x (ndarray): Shape (m,) Input to the model\n",
    "        y (ndarray): Shape (m,) the real values of the prediction\n",
    "        w, b (scalar): Parameters of the model\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, x, y, w, b):\n",
    "        # (scalar): Parameters of the model\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.w = w\n",
    "        self.b = b\n",
    "\n",
    "    \"\"\"\n",
    "    Computes the linear regression function.\n",
    "\n",
    "    Args:\n",
    "        x (ndarray): Shape (m,) Input to the model\n",
    "\n",
    "    Returns:\n",
    "        the linear regression value\n",
    "    \"\"\"\n",
    "\n",
    "    def f_w_b(self, x):\n",
    "        return np.dot(self.x,self.w) + self.b\n",
    "\n",
    "    \"\"\"\n",
    "    Computes the cost function for linear regression.\n",
    "\n",
    "    Returns\n",
    "        total_cost (float): The cost of using w,b as the parameters for linear regression\n",
    "               to fit the data points\n",
    "    \"\"\"\n",
    "\n",
    "    def compute_cost(self):\n",
    "        sum = 0\n",
    "        sum =np.sum((self.y - self.f_w_b(self.x)) ** 2)\n",
    "        total_cost = sum / (2 * len(self.y))\n",
    "        return total_cost\n",
    "\n",
    "    \"\"\"\n",
    "    Computes the gradient for linear regression \n",
    "    Args:\n",
    "\n",
    "    Returns\n",
    "      dj_dw (scalar): The gradient of the cost w.r.t. the parameters w\n",
    "      dj_db (scalar): The gradient of the cost w.r.t. the parameter b     \n",
    "     \"\"\"\n",
    "\n",
    "    def compute_gradient(self):\n",
    "        dj_dw = 0\n",
    "        dj_db = 0\n",
    "        sum = 0\n",
    "\n",
    "        sum = np.sum((self.f_w_b(self.x) - self.y) * self.x)\n",
    "        \n",
    "        dj_dw = sum / (len(self.y))\n",
    "        \n",
    "        sum = 0\n",
    "\n",
    "        sum = np.sum(self.f_w_b(self.x) - self.y)\n",
    "        dj_db = sum / (len(self.y))\n",
    "\n",
    "        return dj_dw, dj_db\n",
    "\n",
    "    \"\"\"\n",
    "    Performs batch gradient descent to learn theta. Updates theta by taking \n",
    "    num_iters gradient steps with learning rate alpha\n",
    "\n",
    "    Args:\n",
    "      alpha : (float) Learning rate\n",
    "      num_iters : (int) number of iterations to run gradient descent\n",
    "    Returns\n",
    "      w : (ndarray): Shape (1,) Updated values of parameters of the model after\n",
    "          running gradient descent\n",
    "      b : (scalar) Updated value of parameter of the model after\n",
    "          running gradient descent\n",
    "      J_history : (ndarray): Shape (num_iters,) J at each iteration,\n",
    "          primarily for graphing later\n",
    "      w_initial : (ndarray): Shape (1,) initial w value before running gradient descent\n",
    "      b_initial : (scalar) initial b value before running gradient descent\n",
    "    \"\"\"\n",
    "\n",
    "    def gradient_descent(self, alpha, num_iters):\n",
    "        # An array to store cost J and w's at each iteration â primarily for graphing later\n",
    "        J_history = []\n",
    "        w_history = []\n",
    "        for i in range(num_iters):\n",
    "            j = self.compute_cost()\n",
    "            J_history.append(j)\n",
    "            self.w=  np.dot(-alpha * self.compute_gradient().dj_dw)\n",
    "            self.b = np.dot(-alpha * self.compute_gradient().dj_db)\n",
    "\n",
    "        w_initial = copy.deepcopy(self.w)  # avoid modifying global w within function\n",
    "        b_initial = copy.deepcopy(self.b)  # avoid modifying global b within function\n",
    "\n",
    "        return self.w, self.b, J_history, w_initial, b_initial\n",
    "\n",
    "\n",
    "def cost_test_obj(x, y, w_init, b_init):\n",
    "    lr = LinearReg(x, y, w_init, b_init)\n",
    "    cost = lr.compute_cost()\n",
    "    return cost\n",
    "\n",
    "\n",
    "def compute_gradient_obj(x, y, w_init, b_init):\n",
    "    lr = LinearReg(x, y, w_init, b_init)\n",
    "    dw, db = lr.compute_gradient()\n",
    "    return dw, db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b65c52be-5ae9-47d1-9f75-1cf0bfa88e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import practica01 as pt\n",
    "import public_tests\n",
    "import time\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1520ce3-254f-4042-b81f-8e4964c8033d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
